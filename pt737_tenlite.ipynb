{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a20ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import memory_profiler\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5eaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    benign = np.loadtxt(\"benign_traffic.csv\", delimiter = \",\")\n",
    "    mirai = np.loadtxt(\"mirai_traffic.csv\", delimiter = \",\")\n",
    "    gafgyt = np.loadtxt(\"gafgyt_traffic.csv\", delimiter = \",\")\n",
    "    alldata = np.concatenate((benign, gafgyt, mirai))\n",
    "    j = len(benign[0])\n",
    "    data = alldata[:, 1:j] \n",
    "    benlabel = alldata[:, 0]\n",
    "    bendata = (data - data.min()) / (data.max() - data.min())\n",
    "    bendata, benmir, benlabel, benslabel = train_test_split(bendata, benlabel, test_size = 0.2, random_state = 42)\n",
    "    return bendata, benmir, benlabel, benslabel\n",
    "\n",
    "traind, testd, trainlbl, testlbl =  data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1941d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=115,activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd26480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d863b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(traind, trainlbl, batch_size = 128, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d55c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\1804499\\AppData\\Local\\Temp\\tmp5ycv_dtq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\1804499\\AppData\\Local\\Temp\\tmp5ycv_dtq\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time lite: 2.626690 sec\n",
      "Training memory lite: 28.175781 mb\n"
     ]
    }
   ],
   "source": [
    "starttc = time.time()\n",
    "startmc = memory_profiler.memory_usage()\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "endtc = time.time()\n",
    "endmc = memory_profiler.memory_usage()\n",
    "train_time_c = endtc - starttc\n",
    "train_memory_c = endmc[0] - startmc[0]\n",
    "\n",
    "print(\"Training time lite: {:2f} sec\".format(train_time_c))\n",
    "print(\"Training memory lite: {:2f} mb\".format(train_memory_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23e0dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"/tmp/pt737_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad648c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326984"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = tflite_models_dir/\"pt737_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd13f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time lite optimize: 0.115974 sec\n",
      "Training memory lite optimize: 0.000000 mb\n"
     ]
    }
   ],
   "source": [
    "startto = time.time()\n",
    "startmo = memory_profiler.memory_usage()\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "endto = time.time()\n",
    "endmo = memory_profiler.memory_usage()\n",
    "\n",
    "train_time_o = endto - startto\n",
    "train_memory_o = endmo[0] - startmo[0]\n",
    "\n",
    "\n",
    "print(\"Training time lite optimize: {:2f} sec\".format(train_time_o))\n",
    "print(\"Training memory lite optimize: {:2f} mb\".format(train_memory_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1cb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "219fc6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "  \n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_traffics = []   \n",
    "  for test_i in testd:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_i = np.expand_dims(test_i, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_i)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    traf = np.argmax(output()[0])\n",
    "    prediction_traffics.append(traf)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_traffics)):\n",
    "    if prediction_traffics[index] == testlbl[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_traffics)\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16388ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9251684253736749\n",
      "Testing time base: 8.884701 sec\n",
      "Testing memory base: 0.000000 mb\n"
     ]
    }
   ],
   "source": [
    "starttesttb = time.time()\n",
    "starttestmb = memory_profiler.memory_usage()\n",
    "\n",
    "print(evaluate_model(interpreter))\n",
    "\n",
    "endttestb = time.time()\n",
    "endtestmb = memory_profiler.memory_usage()\n",
    "test_time_b = endttestb - starttesttb\n",
    "test_memory_b = endtestmb[0] - starttestmb[0]\n",
    "print(\"Testing time base: {:2f} sec\".format(test_time_b))\n",
    "print(\"Testing memory base: {:2f} mb\".format(test_memory_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd1adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
